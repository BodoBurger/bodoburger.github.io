[{"authors":["admin"],"categories":null,"content":"I am a statistician based in Munich, Germany. I hold a Master’s degree in statistics and a Bachelor’s degree in economics. I am interested in all things related to data analysis, e.g. statistics, data science, machine learning, deep learning.\nBeyond modeling and predicting I think it is also important to interpret results (machine learning interpretability, eXplainable AI) and consider economic and social implications of a data driven world.\nIn my spare time, I make electronic music and play the piano. I enjoy going for a hike or on a bicycle tour through the Alps. Besides, I regularly go swimming and play / watch football (aka soccer) and chess.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1575980788,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://bodoburger.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a statistician based in Munich, Germany. I hold a Master’s degree in statistics and a Bachelor’s degree in economics. I am interested in all things related to data analysis, e.g. statistics, data science, machine learning, deep learning.\nBeyond modeling and predicting I think it is also important to interpret results (machine learning interpretability, eXplainable AI) and consider economic and social implications of a data driven world.\nIn my spare time, I make electronic music and play the piano.","tags":null,"title":"Bodo Burger","type":"authors"},{"authors":null,"categories":null,"content":"Resources Unix shell  http://swcarpentry.github.io/shell-novice/ https://en.wikipedia.org/wiki/Bash_%28Unix_shell%29 https://help.ubuntu.com/community/Beginners/BashScripting  ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1575586183,"objectID":"56fa5d9e9bbd80a24d437a6fcd9b991b","permalink":"https://bodoburger.github.io/notes/ubuntu/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/notes/ubuntu/","section":"notes","summary":"Installation of software, configurations, tweaks etc..","tags":null,"title":"Ubuntu Wiki","type":"docs"},{"authors":null,"categories":null,"content":"Resources   Mining of Massive Datasets: free book, MOOC, lecture  Lecture ETH Zürich  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1575586183,"objectID":"c4b04d9bc5225857918e4365397135af","permalink":"https://bodoburger.github.io/notes/big-data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/big-data/","section":"notes","summary":"Data science tools, techniques and resources.","tags":null,"title":"Big Data","type":"docs"},{"authors":null,"categories":null,"content":"Overview  Anaconda is a Python distribution that comes with Conda, a package manager and environment management system.\nResources   Conda docs  Conda cheat sheet  Conda: Myths and Misconceptions  Conda forge (an alternative distribution for conda)  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1575586183,"objectID":"9e1f0897ab07e9b624151ed0d974f75c","permalink":"https://bodoburger.github.io/notes/anaconda/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/anaconda/","section":"notes","summary":"Python distribution and environment manager","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"Cloud computing   Amazon Web Services  Documentation: https://docs.aws.amazon.com/    Microsoft Azure  FloydHub  build, train, and deploy deep learning models    Deployment   Wercker  Website services   Netlify  hosting and serverless backend services for static websites continuous deployment from Git    formspree  website forms    ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1576078779,"objectID":"631c9123afbf91a2a9f87a0f420f80b4","permalink":"https://bodoburger.github.io/notes/cloud-services/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/cloud-services/","section":"notes","summary":"Amazon Web Services, ...","tags":null,"title":"Cloud Services","type":"docs"},{"authors":null,"categories":null,"content":"Disable middle click paste https://wiki.ubuntuusers.de/GNOME_Tweak_Tool/\nDisable looking for wifi printer /etc/cups/cups-browsed.conf ## Change BrowseRemoteProtocols dnssd cups to BrowseRemoteProtocols none  https://ubuntuforums.org/showthread.php?t=2330752\nKeyboardshortcut Power off Adding shortcut for Power off screen by setting custom shortcut:\ngnome-session-quit --power-off\nKein Lock screen nach Suspend https://www.techgrube.de/tutorials/ubuntu-sperrbildschirm-nach-standby-deaktivieren\n\u0026ldquo;Die gewünschte Einstellung findet man dann unter org -\u0026gt; Gnome -\u0026gt; Desktop -\u0026gt; screensaver. Hier entfernt man einfach bei ubuntu-lock-on-suspend das Häkchen.\u0026rdquo;\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"1e797d211322855926bfb53ad0cd1990","permalink":"https://bodoburger.github.io/notes/ubuntu/basic-tweaks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/ubuntu/basic-tweaks/","section":"notes","summary":"Disable middle click paste https://wiki.ubuntuusers.de/GNOME_Tweak_Tool/\nDisable looking for wifi printer /etc/cups/cups-browsed.conf ## Change BrowseRemoteProtocols dnssd cups to BrowseRemoteProtocols none  https://ubuntuforums.org/showthread.php?t=2330752\nKeyboardshortcut Power off Adding shortcut for Power off screen by setting custom shortcut:\ngnome-session-quit --power-off\nKein Lock screen nach Suspend https://www.techgrube.de/tutorials/ubuntu-sperrbildschirm-nach-standby-deaktivieren\n\u0026ldquo;Die gewünschte Einstellung findet man dann unter org -\u0026gt; Gnome -\u0026gt; Desktop -\u0026gt; screensaver. Hier entfernt man einfach bei ubuntu-lock-on-suspend das Häkchen.\u0026rdquo;","tags":null,"title":"Basic tweaks and configuration","type":"docs"},{"authors":null,"categories":null,"content":"Software list  APT  chromium-browser TexLive: sudo apt install texlive-full (4GB) R ( more info) Scribus VLC  darktable: bash sudo apt install darktable   Snap  keepassxc gimp go (and hugo) node onlyoffice Octave (Matlab alternative)   Flatpak  libreoffice Epub: Bookworm   .deb (manually)   Rstudio  VS Code (.deb package installs apt repo)  Master PDF   .sh  Anaconda    Alarm clock and timer https://wiki.ubuntuusers.de/Alarm_Clock/\nsudo apt install alarm-clock-applet sudo apt install sound-icons # folder location: /usr/share/sounds/sound-icons/.  Nvidia drivers \u0026ldquo;Software \u0026amp; Updates \u0026ndash;\u0026gt; Additional Drivers\u0026rdquo;\nPackage management  https://book.dpmb.org/debian-paketmanagement.chunked/ch03s02.html https://book.dpmb.org/debian-paketmanagement.chunked/ch03s03.html  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"47c7293d2f1619261b428e44c1aac60c","permalink":"https://bodoburger.github.io/notes/ubuntu/install-software/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/ubuntu/install-software/","section":"notes","summary":"Software list  APT  chromium-browser TexLive: sudo apt install texlive-full (4GB) R ( more info) Scribus VLC  darktable: bash sudo apt install darktable   Snap  keepassxc gimp go (and hugo) node onlyoffice Octave (Matlab alternative)   Flatpak  libreoffice Epub: Bookworm   .deb (manually)   Rstudio  VS Code (.deb package installs apt repo)  Master PDF   .sh  Anaconda    Alarm clock and timer https://wiki.","tags":null,"title":"Installing software","type":"docs"},{"authors":null,"categories":null,"content":"Extracting photos from multiple PDFs using pdfunite and pdfimages pdfunite *.pdf allphotos.pdf pdfimages -j ‘allphotos.pdf’ image  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"c971053ec979f8839330128ab825df80","permalink":"https://bodoburger.github.io/notes/ubuntu/pdf/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/ubuntu/pdf/","section":"notes","summary":"Extracting photos from multiple PDFs using pdfunite and pdfimages pdfunite *.pdf allphotos.pdf pdfimages -j ‘allphotos.pdf’ image  ","tags":null,"title":"PDF","type":"docs"},{"authors":null,"categories":null,"content":"Install libopenblas at first:\nhttps://www.r-bloggers.com/why-is-r-slow-some-explanations-and-mklopenblas-setup-to-try-to-fix-this/\nInstallation https://cloud.r-project.org/bin/linux/ubuntu/README.html\n# adding secure apt key: sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 # adding cran-mirror for Ubuntu 18.04: sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/' # archive server sudo add-apt-repository 'deb http://ubuntu.mirror.lrz.de/ubuntu/ bionic-backports main restricted universe' # installing r-base and r-dev sudo apt update sudo apt install r-base r-base-dev   RStudio: https://www.rstudio.com/products/rstudio/download/  Dependencies of R packages #\u0026quot;rgl\u0026quot; sudo apt install libcgal-dev libglu1-mesa-dev libglu1-mesa-dev libfreetype6-dev # \u0026quot;devtools\u0026quot;: sudo apt install libcurl4-openssl-dev libssl-dev # \u0026quot;XML\u0026quot;: sudo apt install libxml2-dev # \u0026quot;rattle\u0026quot;: sudo apt install libcanberra-gtk-module sudo apt install wajig wajig install libgtk2.0-dev libxml2-dev # \u0026quot;cairo\u0026quot;: sudo apt-get install libcairo2-dev # \u0026quot;sbrl\u0026quot; sudo apt install libgsl-dev  RWeka: java –version sudo apt install default-jre default-jdk javac -version  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"81c8dfa30ccd967d244209e08625f622","permalink":"https://bodoburger.github.io/notes/ubuntu/r-stats/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/ubuntu/r-stats/","section":"notes","summary":"Install libopenblas at first:\nhttps://www.r-bloggers.com/why-is-r-slow-some-explanations-and-mklopenblas-setup-to-try-to-fix-this/\nInstallation https://cloud.r-project.org/bin/linux/ubuntu/README.html\n# adding secure apt key: sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 # adding cran-mirror for Ubuntu 18.04: sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/' # archive server sudo add-apt-repository 'deb http://ubuntu.mirror.lrz.de/ubuntu/ bionic-backports main restricted universe' # installing r-base and r-dev sudo apt update sudo apt install r-base r-base-dev   RStudio: https://www.rstudio.com/products/rstudio/download/  Dependencies of R packages #\u0026quot;rgl\u0026quot; sudo apt install libcgal-dev libglu1-mesa-dev libglu1-mesa-dev libfreetype6-dev # \u0026quot;devtools\u0026quot;: sudo apt install libcurl4-openssl-dev libssl-dev # \u0026quot;XML\u0026quot;: sudo apt install libxml2-dev # \u0026quot;rattle\u0026quot;: sudo apt install libcanberra-gtk-module sudo apt install wajig wajig install libgtk2.","tags":null,"title":"R, packages and its dependencies","type":"docs"},{"authors":null,"categories":null,"content":"http://thinkwiki.de/TLP_-_Linux_Stromsparen\nhttp://linrunner.de/en/tlp/tlp.html\nsudo apt install tlp tlp-rdw tp-smapi-dkms acpi-call-dkms # bluetooth off at startup: gksudo gedit /etc/default/tlp # does not work with WAYLAND DEVICES_TO_DISABLE_ON_STARTUP=\u0026quot;bluetooth\u0026quot; # Akku-Ladeschwellen vorübergehend auf Maximum setzen sudo tlp fullcharge [ BAT0 | BAT1 ] # Akku einmalig bis zur oberen Schwelle laden sudo tlp chargeonce [ BAT0 | BAT1 ]  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"5e0ce29ce34c7a08859a9466f4d65ff4","permalink":"https://bodoburger.github.io/notes/ubuntu/tlp/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/ubuntu/tlp/","section":"notes","summary":"http://thinkwiki.de/TLP_-_Linux_Stromsparen\nhttp://linrunner.de/en/tlp/tlp.html\nsudo apt install tlp tlp-rdw tp-smapi-dkms acpi-call-dkms # bluetooth off at startup: gksudo gedit /etc/default/tlp # does not work with WAYLAND DEVICES_TO_DISABLE_ON_STARTUP=\u0026quot;bluetooth\u0026quot; # Akku-Ladeschwellen vorübergehend auf Maximum setzen sudo tlp fullcharge [ BAT0 | BAT1 ] # Akku einmalig bis zur oberen Schwelle laden sudo tlp chargeonce [ BAT0 | BAT1 ]  ","tags":null,"title":"TLP – Linux Advanced Power Management","type":"docs"},{"authors":null,"categories":null,"content":"Mount sudo mount -o remount,rw /media/\u0026lt;storage-name\u0026gt;\nError: Can\u0026rsquo;t format USB storage I got this fixed by doing the following\nType disks and launch the program, select the disk or drive you want to format, press CTRL+F and click format.\nAfter formatting, the disk or drive would be unallocated, therefore you\u0026rsquo;ll have to create a partition by using the plus button on the screen.. Then insert the name you\u0026rsquo;ll like to use as the drive or disk name then click on create. Enjoy\u0026hellip;.\nhttps://askubuntu.com/questions/769079/cant-format-ubuntu-installation-stick/769094\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"5ba515eec1d68f974279f69c9075b556","permalink":"https://bodoburger.github.io/notes/ubuntu/usb-storage/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/ubuntu/usb-storage/","section":"notes","summary":"Mount sudo mount -o remount,rw /media/\u0026lt;storage-name\u0026gt;\nError: Can\u0026rsquo;t format USB storage I got this fixed by doing the following\nType disks and launch the program, select the disk or drive you want to format, press CTRL+F and click format.\nAfter formatting, the disk or drive would be unallocated, therefore you\u0026rsquo;ll have to create a partition by using the plus button on the screen.. Then insert the name you\u0026rsquo;ll like to use as the drive or disk name then click on create.","tags":null,"title":"USB storage","type":"docs"},{"authors":null,"categories":null,"content":"  Documentation  For a clean uninstall, first install anaconda-clean package,\nconda install anaconda-clean anaconda-clean  then:\nrm -rf ~/anaconda3  ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"786a15ed4c759b79ba5722a7a83370ae","permalink":"https://bodoburger.github.io/notes/anaconda/anaconda-uninstall/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/notes/anaconda/anaconda-uninstall/","section":"notes","summary":"  Documentation  For a clean uninstall, first install anaconda-clean package,\nconda install anaconda-clean anaconda-clean  then:\nrm -rf ~/anaconda3  ","tags":null,"title":"Uninstalling Anaconda","type":"docs"},{"authors":["Bodo Burger"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572808667,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://bodoburger.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":null,"categories":null,"content":"  Abstract Example: Bike Sharing Data Model Training Analysis  R package References   Abstract Supervised machine learning models are mostly black boxes. The method we propose tries to improve understanding of these black boxes. The goal is to find a way to quantify effect sizes of features. Average marginal effects are used in social sciences to determine effect sizes of logistic regression models. Applying this method to a machine learning model usually does not adequately represent the non-convex, non-monotonic response function. There are graphical methods like partial dependence plots or accumulated local effect plots that visualize the response functions but do not offer a quantitative interpretation. First, we use one of the latter methods to identify intervals within the response function is relatively stable. Second, we report some estimate of the feature effect separately for each interval. Our method determines the number of necessary intervals automatically.\n Example: Bike Sharing Data The following examples shows how the method can help to understand heterogeneous feature effects. We apply the method to the Bike Sharing dataset (Fanaee-T and Gama 2013) which was further processed by Molnar (2018). See table 1 for an overview of all the features. The target cnt is the number of bicycles lent by a bicycle sharing company per day. The features comprise calendrical and meteorological information for each day.\n Table 1: Excerpt of the Bike Sharing dataset  season yr mnth holiday weekday weathersit temp hum windspeed cnt days_since_2011    SPRING 2011 JAN 0 SAT MISTY 8.18 80.6 10.8 985 0  SPRING 2011 JAN 0 SUN MISTY 9.08 69.6 16.7 801 1  SPRING 2011 JAN 0 MON GOOD 1.23 43.7 16.6 1349 2  SPRING 2011 JAN 0 TUE GOOD 1.40 59.0 10.7 1562 3  SPRING 2011 JAN 0 WED GOOD 2.67 43.7 12.5 1600 4  SPRING 2011 JAN 0 THU GOOD 1.60 51.8 6.0 1606 5    Model Training We use a linear model (R Core Team 2019), an SVM (Meyer et al. 2019), a random decision forest (Breiman et al. 2018) and gradient boosting (Greenwell et al. 2019). We compare the performance of all models and the performance of predicting the mean for each observation on a hold-out test set (see table 2). The linear model performs relatively well but we can improve by using a more complex machine learning model even without extensive tuning.\n Table 2: Mean squared error, root mean squared log error, and R squared for hold-out test set   mean(y) lm svm rf gbm    mse 3.75e+06 5.30e+05 4.33e+05 4.22e+05 4.12e+05  rmsle 5.93e-01 2.36e-01 2.44e-01 2.61e-01 2.30e-01  rsq 0.00e+00 8.59e-01 8.85e-01 8.88e-01 8.90e-01     Analysis Now analyse how changing feature values influences the predicted number of bikes. We focus on the three numerical features temp (temperature in degree Celsius), hum (humidity in percent) and windspeed (in kilometers per hour). We apply our method to each of the complex models with default settings. The output in R looks as follows:\n## lm: ## temp hum windspeed ## 98.2 -13.7 -40.1 ## SVM (temp) ## [-5.221, 19.26) [19.26, 32.498] ## 128.11 3.87 ## SVM (hum) ## [18.792, 56.792) [56.792, 93.957] ## 7.19 -32.71 ## SVM (windspeed) ## [2.834, 14.876) [14.876, 34] ## -22.7 -64.7 ## RF (temp) ## [-5.221, 20.278) [20.278, 32.498] ## 104.5 -62.7 ## RF (hum) ## [18.792, 64.667) [64.667, 93.957] ## -1.18 -31.97 ## RF (windspeed) ## [2.834, 18.417) [18.417, 24.251) [24.251, 34] ## -16.46 -78.30 -1.64 ## GBM (temp) ## [-5.221, 16.792) [16.792, 26.075) [26.075, 32.498] ## 124.2 13.9 -239.7 ## GBM (hum) ## [18.792, 64.667) [64.667, 83.792) [83.792, 87.25) [87.25, 93.957] ## -3.86 -39.63 -227.00 91.19 ## GBM (windspeed) ## [2.834, 8.584) [8.584, 22.959) [22.959, 24.251) [24.251, 34] ## -5.32e+01 -1.85e+01 -5.04e+02 6.60e-14 The marginal effect of the linear model is equal to the model coefficients. So according to the model an increase of the temperature by 1° Celsius leads to a predicted increase of \\(98.188\\). rented bicycles per day. This seems plausible for an average day. The higher the temperature the more people are willing to go by bike. But one could easily imagine that a temperature rise on a hot day will make people less likely rent a bike to avoid physical exertion. This is exactly what the results of the complex models suggest. Below 20° the SVM predicts an increase of \\(128.106\\) bikes per day for an additional degree Celsius. Above 20° the effect becomes negative and very small \\((3.867)\\). The results of the random forest show two cutoff points. At around 13° the positive marginal effect becomes smaller in size and above 25° the effect is negative. The effect for gradient boosting is partitioned into four intervals. The effect of the three intervals below 27° are positive, above 27° it is negative, similarly to the results of the other two models. However, the absolute values of the effect fluctuate substantially for gradient boosting.\nFor humidity the linear model predicts a negative effect. For the SVM the effect is positive up to around 43%. Between 43% and 65% the effect is negative but smaller in size. Above 65% it is negative and four times bigger than in the previous interval. The results for the random forest and gradient boosting both show very small effects below roughly 65% humidity. Above this point both models predict a decrease of rented bicycles with rising humidity. The histogram (figure 1) explains why the effect for humidity is probably non-monotonic. Humidity usually is between 50% to 75%. Values outside this range indicate more extreme weather conditions. If uncommonly dry or wet air reduces people’s desire to ride a bike we will expect a positive effect on the number of rented bikes if humidity is below the familiar range, and a negative effect if it is above.\n Figure 1: Histogram for feature humidity of the Bike Sharing dataset.  Wind makes cycling less attractive, so one associates higher wind speed with a reduced willingness to rent a bike. The linear model predicts a negative effect (\\(-40.149\\)). For both SVM and random forest our method proposes a negative effect that is constant over the whole feature distribution. Consequently, in the case of wind speed a linear model seems to be appropriate to represent the relationship. Gradient boosting shows a negative effect for five intervals, the reported values are not very stable, again.\nIn this exemplary application we showed that the linear model does not suffice to represent the varying response function types. A user may come to wrong conclusions about the number of rented bikes depending on the weather conditions of the day. The proposed method enables the user to make quantitative statements as if he was using a linear model while preserving the non-linear, non-monotonic relationship where necessary. Thus, he can combine a better performing model with a comprehensible interpretation. The results for the gradient boosting model are less convincing. Due to the stepped response function the model is less appropriate for making quantitative statements about the feature effect. The estimates fluctuate between high values and values close to zero.\n Figure 2: Bike sharing data. Results SVM.   Figure 3: Bike sharing data. Results gradient boosting.   Figure 4: Bike sharing data. Results random forest.    R package The method is implemented in R supporting a variety of models out of the box. Source code and more information can be found on GitHub: https://github.com/BodoBurger/intame\n References Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression. https://CRAN.R-project.org/package=randomForest.\n Fanaee-T, Hadi, and Joao Gama. 2013. “Event Labeling Combining Ensemble Detectors and Background Knowledge.” Progress in Artificial Intelligence. Springer Berlin Heidelberg, 1–15. https://doi.org/10.1007/s13748-013-0040-3.\n Greenwell, Brandon, Bradley Boehmke, Jay Cunningham, and GBM Developers. 2019. Gbm: Generalized Boosted Regression Models. https://CRAN.R-project.org/package=gbm.\n Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2019. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), Tu Wien. https://CRAN.R-project.org/package=e1071.\n Molnar, Christoph. 2018. Interpretable Machine Learning - a Guide for Making Black Box Models Explainable. Creative Commons. https://christophm.github.io/interpretable-ml-book/.\n R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n   ","date":1554508800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573048913,"objectID":"39362d474a2a1d789916b3f098febe12","permalink":"https://bodoburger.github.io/project/2019-feature-effects/","publishdate":"2019-04-06T00:00:00Z","relpermalink":"/project/2019-feature-effects/","section":"project","summary":"We estimate interval-based feature effects in supervised learning models to improve interpretability of black box models.","tags":["Interpretable ML","Machine Learning","r-stats"],"title":"Feature Effects in Machine Learning Models","type":"project"},{"authors":["Bodo Burger"],"categories":["Tutorials"],"content":" I recently stumbled upon this bread recipe. It’s quickly prepared, the bread tastes great and is full of valuable ingredients (only oats, nuts and seeds). However, being homemade it does not come with a nutrition table. The following shows an easy way to create one.\nWe put the recipe into a spreadsheet (recipe). Another spreadsheet contains the nutritional values of the macro nutrients of each ingredient (food stats). We combine these using R to get the nutrition table. Then, we look at an alternative to manually creating a spreadsheet with nutritional information by using an online database. As a bonus, we can calculate the price of the recipe.\nDownloading Google Sheets to R A simple way to import Google Sheets to R is the gsheet package. We only need to supply the sharing link. It returns a tibble.\nfood_stats = gsheet::gsheet2tbl(\u0026quot;https://docs.google.com/spreadsheets/d/1qgo8Yefb5nx5PVElZvmf6nSDI6RfN2ofd8CeMuSklHk\u0026quot;) recipe = gsheet::gsheet2tbl(\u0026quot;https://docs.google.com/spreadsheets/d/1C0AwjQYrudrV3ZLgQJZnCr9La7OVftRTZn3QKMrJx5E\u0026quot;) food_stats contains more ingredients than we need for our bread recipe. So when we merge both data frames we only want to keep the rows that contain the ingredients of the recipe. This is done by left_join() from the dplyr package.\nlibrary(dplyr) bread_ingredient_stats = left_join(recipe, food_stats, \u0026quot;Description\u0026quot;)  Calculating the nutritional values We have 10 ingredients. First, we create a vector that gives us the quantity of each ingredient in grams, then we select the columns that are relevant for the nutrition table.\nnutrient_names = c(\u0026quot;Calories (kcal)\u0026quot;, \u0026quot;Total Fat\u0026quot;, \u0026quot;Saturated Fat\u0026quot;, \u0026quot;Total Carbs\u0026quot;, \u0026quot;Sugar\u0026quot;, \u0026quot;Dietary Fiber\u0026quot;, \u0026quot;Protein\u0026quot;) quantities = select(bread_ingredient_stats, \u0026quot;Quantity (gr)\u0026quot;)[[1]] nutrition_values = bread_ingredient_stats %\u0026gt;% select(nutrient_names) The following calculation gives us the quantity of each macro nutrient in our bread per 100g:\nnutrition_table = colSums(nutrition_values * quantities) / sum(quantities) Finally, we can print our nutrition table:\nknitr::kable(nutrition_table, digits = 1, col.names = \u0026quot;per 100g\u0026quot;, caption = \u0026quot;Nutrition table\u0026quot;)  Table 1: Nutrition table   per 100g    Calories (kcal) 307.3  Total Fat 22.5  Saturated Fat 4.7  Total Carbs 12.2  Sugar 0.5  Dietary Fiber 10.6  Protein 12.6    Calorie-wise very similar to your typical brown bread, but rich in fat. Trust me, the bread is very filling, so you won’t be able to eat too much of it anyways. And how much does it cost?\nprices = select(bread_ingredient_stats, \u0026quot;Price (€)\u0026quot;)[[1]] packaging = select(bread_ingredient_stats, \u0026quot;Packaging (g)\u0026quot;)[[1]] (price_total = sum(prices / packaging * quantities, na.rm = TRUE)) ## [1] 3.208962 One loaf of bread is 3.21€ (not including energy and time) weighing 910 grams (raw ingredients). I think that is a fair price for a bread I can eat from for a whole week.\n Using the API of a nutrition database Instead of manually creating a spreadsheet for the nutritional values of each ingredient we can fetch the information from on online database. We use openfoodfacts. It’s a crowd-sourced database of food stats. To identify a product we need a barcode for each ingredient which I added to the recipe spreadsheet. The openfoodfacts API returns a JSON file which we can convert to a list using the rjson package. We write two helper functions to fetch and extract the relevant information.\nlibrary(\u0026quot;rjson\u0026quot;) fetch_json = function(barcode, url = \u0026quot;https://world.openfoodfacts.org/api/v0/product/\u0026quot;) { query = paste0(url, barcode, \u0026quot;.json\u0026quot;) fromJSON(file = query) } extract_nutrition_values = function(food_list, nutriments = c(\u0026quot;energy_100g\u0026quot;, \u0026quot;fat_100g\u0026quot;, \u0026quot;saturated-fat_100g\u0026quot;, \u0026quot;carbohydrates_100g\u0026quot;, \u0026quot;sugars_100g\u0026quot;, \u0026quot;fiber_100g\u0026quot;, \u0026quot;proteins_100g\u0026quot;)) { nv = setNames(rep(0, length(nutriments)), nutriments) tmp = unlist(food_list$product$nutriments[nutriments]) nv[names(tmp)] = tmp nv } barcodes = bread_ingredient_stats$Barcode[-10] # water does not have a barcode nutrition_values_api = matrix(0, nrow = 10, ncol = length(nutrition_values), dimnames = list(1:10, nutrient_names)) for(i in seq_along(barcodes)) { food_list_tmp = fetch_json(barcodes[i]) nutrition_values_api[i,] = extract_nutrition_values(food_list_tmp) } nutrition_values_api has the same structure as nutrition_values from above, so we can proceed as before:\n(nutrition_table_api = colSums(nutrition_values_api * quantities) / sum(quantities)) ## Calories (kcal) Total Fat Saturated Fat Total Carbs ## 1344.0329670 22.4906593 4.7263736 12.3516484 ## Sugar Dietary Fiber Protein ## 0.4923077 8.9291209 12.5313187 The results for the macro nutrients differ slightly which is expected because we changed the data source. However, the value for calories quadrupled because the API reported energy in kilojoule (kJ) instead of kilocalories. To correct for this we divide the value by \\(4.1858\\).\nnutrition_table_api[1] = nutrition_table_api[1] / 4.1858 knitr::kable(nutrition_table_api, digits = 1, col.names = \u0026quot;per 100g\u0026quot;, caption = \u0026quot;Nutrition table\u0026quot;)  Table 2: Nutrition table   per 100g    Calories (kcal) 321.1  Total Fat 22.5  Saturated Fat 4.7  Total Carbs 12.4  Sugar 0.5  Dietary Fiber 8.9  Protein 12.5    And we are done!\n ","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572981912,"objectID":"6dfd57fb90f671ecab5d92e8407cc7d8","permalink":"https://bodoburger.github.io/post/2019-04-nutrition-table-google-sheets/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/post/2019-04-nutrition-table-google-sheets/","section":"post","summary":"I recently stumbled upon this bread recipe. It’s quickly prepared, the bread tastes great and is full of valuable ingredients (only oats, nuts and seeds). However, being homemade it does not come with a nutrition table. The following shows an easy way to create one.\nWe put the recipe into a spreadsheet (recipe). Another spreadsheet contains the nutritional values of the macro nutrients of each ingredient (food stats). We combine these using R to get the nutrition table.","tags":["r-stats"],"title":"Use R, Google Sheets and a nutrition API to calculate a nutrition table","type":"post"},{"authors":null,"categories":["Book reviews"],"content":" The book gives an overview of common methods that help to better understand machine learning models. You can support the author by buying the book on leanpub. There is a free online version of the book, too.\nIntroduction The beginning of the book covers three short stories that illustrate the detrimental consequences of a world controlled by black box machine learning models (1.1). They serve as motivation for why we want to use methods that improve understanding of opaque models. The ultimate goal of these methods is that a human can understand a model so that he can consistently predict its results.\nChapter 2 lays the foundation for the discussion on machine learning interpretability by answering the following questions:\n Why is interpretation important and when do we need it (2.1)? How can we classify different interpretation methods (2.2)?  intrinsic vs post-hoc methods result of the method model-specific vs model-agnostic local vs global  Which part of a model do we want to inspect (2.3)? How do we evaluate the interpretation (2.4)? What does a human need to know to understand a black box model (2.6)?  The presented interpretation methods are repeatedly applied to three freely available data sets representing different kinds of prediction tasks: daily bike rentals (regression), cancer risk factors (classification) and YouTube spam comments (text classification). Chapter 3 introduces the datasets in more detail.\n Interpretable models This chapter presents models that are interpretable by itself. For Molnar these are linear regression, logistic regression, decision trees, decision rules, RuleFit (Friedman and Popescu, 2005), naive Bayes and k-nearest neighbors.\nThese models have in common that the result is accessible to the user without further steps. They differ in regards to linearity, monotonicity, the possibility to include feature interactions and the tasks they can handle.\nMolnar concludes the discussion of each method with a comparison of its advantages and disadvantages. E.g. the apparent simplicity of linear models is opposed by the difficulty to incorporate nonlinearity, the low predictive performance and the potentially unintuitive interpretation of the coefficients due to correlated features.\nThe following table is an overview of implementations of interpretable models both for R and Python:\n   Method\n  R   Python     linear model   lm()   sklearn.linear_model.LinearRegression()     logistic model   glm(formula, binomial(link = “logit”))   sklearn.linear_model.LogisticRegression()     decision tree   rpart()   sklearn.tree    decision rule   OneR()   BRLC() (skater)   RuleFit   pre()   RuleFit() or SkopeRules()     Naive Bayes   naiveBayes()  sklearn.naive_bayes     k-nearest neighbors   kknn()  sklearn.neighbors    Model-agnostic methods A model-agnostic interpretability method is applied after a model is trained to make the result more accessible or transparent. Best case the method is flexible enough to be applied on any model.\n   Method\n  R   Python     Partial Dependence Plot   Packages: mlr, pdp, iml, intame   sklearn.inspection.plot_partial_dependence()     Individual Conditional Expectation   Packages: iml, pdp, ICEbox       Accumulated Local Effect   Packages: iml, ALEPlot, intame       ","date":1551139200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576180599,"objectID":"312e1aa751175120a15d82bfcb37075d","permalink":"https://bodoburger.github.io/post/2019-02-interpretable-ml-book/","publishdate":"2019-02-26T00:00:00Z","relpermalink":"/post/2019-02-interpretable-ml-book/","section":"post","summary":"The book gives an overview of common methods that help to better understand machine learning models. You can support the author by buying the book on leanpub. There is a free online version of the book, too.\nIntroduction The beginning of the book covers three short stories that illustrate the detrimental consequences of a world controlled by black box machine learning models (1.1). They serve as motivation for why we want to use methods that improve understanding of opaque models.","tags":["Interpretable ML","explainable AI"],"title":"Interpretable Machine Learning by Christoph Molnar","type":"post"},{"authors":[],"categories":["cheatsheets"],"content":"Table of Contents  Useful articles / resources  Basics Interesting discussions on Git GitHub   Branches  Change branch without committing changes: stash and pop Create a local branch, push it to a remote repository and track it Delete local branch   Configuration  Show or change Git username or email address   Index  Remove files from the index without removing them from disc   Merging  Merge master into feature branch before making a PR   Remote  Push local repository to existing remote Show or change remote   Submodules  Add a submodule Download files to empty submodule directory Remove a submodule (leaving no trace)     This blog post combines both a collection of useful resources on Git and a cheat sheet for git commands I googled repeatedly. It will be updated from time to time.\nUseful articles / resources Basics   Git reference manual  Pro Git book (2nd, 2014)  Git for beginners on stackoverflow  git - the simple guide  The beginner\u0026rsquo;s guide to contributing to a GitHub project  On undoing, fixing, or removing commits in git  Git pretty chart  Interesting discussions on Git   A successful Git branching model  How to Write a Git Commit Message  Code Reviews: Before You Even Run The Code  What is the benefit of gits two stage commit process  Why would I want to stage before committing?  GitHub   Keep your fork up to date with the original repo via GitHub browser interface ( stackoverflow)   Branches Change branch without committing changes: stash and pop Want to have a look at another branch without committing changes done so far? Put them in a stash where they can hide until you switch back.\n$ git stash # on the original branch $ git checkout other-branch # do some stuff on the other branch $ git checkout original-branch $ git stash pop  More about git-stash.\nCreate a local branch, push it to a remote repository and track it $ git checkout -b MyNewBranch # create and switch to new branch # do some stuff $ git push -u origin MyNewBranch  Delete local branch $ git branch -d MyLocalBranch  Configuration Show or change Git username or email address $ git config --list # repository-specific settings $ git config --list --global # global git settings $ git config user.name \u0026quot;Enrico Pallazzo\u0026quot; $ git config user.email \u0026quot;enrico.pallazzo@lapd.com\u0026quot;  The global settings are stored in the Git config file in the HOME directory (~/.gitconfig), repository-specific settings are found at .git/config in the respective repository folder.\nIndex Remove files from the index without removing them from disc If you forgot to add a file to .gitignore:\n$ git rm -rf --cached file-name  The file is now untracked and can be added to .gitignore. Then, you can commit the deletion and the modified gitignore file.\nMerging Merge master into feature branch before making a PR $ git checkout master $ git pull $ git checkout new-feature $ git add *files-and-changes* $ git commit -m \u0026quot;feature description\u0026quot; $ git reset HEAD --hard # removes all uncommited files $ rm *untracked-files* # to prevent merge conflicts $ git merge master # resolve potential merge conflicts $ git commit -m \u0026quot;resolved mergeconflicts | merged master\u0026quot; $ git push origin new-feature  Remote Push local repository to existing remote $ git remote add origin git@github.com:USERNAME/REPOSITORY.git $ git push --all --set-upstream origin  Show or change remote In this example we switch from HTTPS to SSH:\n$ git remote -v \u0026gt; origin https://github.com/USERNAME/REPOSITORY.git (fetch) \u0026gt; origin https://github.com/USERNAME/REPOSITORY.git (push) $ git remote set-url origin git@github.com:USERNAME/REPOSITORY.git $ git remote -v \u0026gt; origin git@github.com:USERNAME/REPOSITORY.git (fetch) \u0026gt; origin git@github.com:USERNAME/REPOSITORY.git (push)  Submodules https://git-scm.com/docs/git-submodule\nAdd a submodule git submodule add git@github.com:USERNAME/REPOSITORY.git PATH/TO/SUBMODULEDIR  Download files to empty submodule directory When cloning a repository with submodules and the submodule directories are empty:\ngit submodule update --init --recursive  Remove a submodule (leaving no trace) git rm PATH/TO/SUBMODULEDIR rm -rf .git/modules/PATH/TO/SUBMODULEDIR git config -f .git/config --remove-section submodule.PATH/TO/SUBMODULEDIR 2\u0026gt; /dev/null  ","date":1499731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574366930,"objectID":"ba2e1cd008d9fa931df23692cc4b564a","permalink":"https://bodoburger.github.io/post/2017-07-git-cheat-sheet/","publishdate":"2017-07-11T00:00:00Z","relpermalink":"/post/2017-07-git-cheat-sheet/","section":"post","summary":"Table of Contents  Useful articles / resources  Basics Interesting discussions on Git GitHub   Branches  Change branch without committing changes: stash and pop Create a local branch, push it to a remote repository and track it Delete local branch   Configuration  Show or change Git username or email address   Index  Remove files from the index without removing them from disc   Merging  Merge master into feature branch before making a PR   Remote  Push local repository to existing remote Show or change remote   Submodules  Add a submodule Download files to empty submodule directory Remove a submodule (leaving no trace)     This blog post combines both a collection of useful resources on Git and a cheat sheet for git commands I googled repeatedly.","tags":["git"],"title":"Git Resources / Cheat Sheet","type":"post"},{"authors":null,"categories":null,"content":" The goal of the project was to quantify the relative importance of different metabolic pathways for coronary heart disease and type 2 diabetes. We analyzed data from the KORA study for which more than 15000 people are repeatedly medically examined since 1984. The main features of the analysis were 47 different biomarkers (see the image above) that represent different metabolic pathways. Additionally we controlled for several personal characteristics like sex or age. The target features were the incidence of the disease and the time until the incidence. Before the analysis missing data was imputed. We modeled the data using a Cox proportional hazards model. The case-cohort study design (Barlow 1994) was taken into account by weighing the data according to Barlow et al. (1999) upon request of our project partners. Because this weighing method is not supported by the R package survival (Therneau 2015) we had to implement the routine by ourselves. The estimation of the relative contribution of different biomarkers to the risk of the disease was done as proposed by Montonen et al. (2011). Finally, estimations from multiple imputations had to be combined following Rubin’s rules (Rubin 1987).\nA paper using the results from this project was published in March 2020 (Huth et al “Biomarker-defined pathways for incident type 2 diabetes and coronary heart disease”).\nReferences Barlow, William E. 1994. “Robust Variance Estimation for the Case-Cohort Design.” Biometrics. JSTOR, 1064–72.\n Barlow, William E, Laura Ichikawa, Dan Rosner, and Shizue Izumi. 1999. “Analysis of Case-Cohort Designs.” Journal of Clinical Epidemiology 52 (12). Elsevier: 1165–72.\n Montonen, Jukka, Dagmar Drogan, Hans-Georg Joost, Heiner Boeing, Andreas Fritsche, Erwin Schleicher, Matthias B Schulze, and Tobias Pischon. 2011. “Estimation of the Contribution of Biomarkers of Different Metabolic Pathways to Risk of Type 2 Diabetes.” European Journal of Epidemiology 26 (1). Springer: 29–38.\n Rubin, D.B. 1987. Multiple Imputation for Nonresponse in Surveys. Wiley Series in Probability and Statistics. Wiley.\n Therneau, Terry M. 2015. A Package for Survival Analysis in S. https://CRAN.R-project.org/package=survival.\n   ","date":1491523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585064468,"objectID":"86e17592eb77172aca68ed68ede2a528","permalink":"https://bodoburger.github.io/project/2017-biomarker-helmholtz/","publishdate":"2017-04-07T00:00:00Z","relpermalink":"/project/2017-biomarker-helmholtz/","section":"project","summary":"Student consulting project for the Institut for Epidemiology on the association of metabolic pathways with coronary heart disease and diabetes.","tags":["Health Sector"],"title":"Data Analysis for Helmholtz Zentrum München","type":"project"},{"authors":null,"categories":null,"content":"","date":1454112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573155717,"objectID":"050f71dd5bcbef30488d6fadf6d150cd","permalink":"https://bodoburger.github.io/project/2016-fundamentals-neural-networks/","publishdate":"2016-01-30T00:00:00Z","relpermalink":"/project/2016-fundamentals-neural-networks/","section":"project","summary":"Seminar paper on why do neural nets work, essential building blocks of feedforward neural nets and training via gradient descent and back-propagation.","tags":["Deep Learning","Artificial Intelligence","Neural Networks"],"title":"Fundamentals of Neural Networks","type":"project"},{"authors":["Bodo Burger"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572808667,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://bodoburger.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":null,"categories":null,"content":"","date":1409011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573159340,"objectID":"73a5528eca9c06ddd0b86becf7e88286","permalink":"https://bodoburger.github.io/project/2014-german-healthcare-system/","publishdate":"2014-08-26T00:00:00Z","relpermalink":"/project/2014-german-healthcare-system/","section":"project","summary":"Literature review on whether healthcare insurances can select for low-risk clients and how privately and statutory insured people are treated differently by healthcare providers.","tags":["Health Sector","Economics"],"title":"German Healthcare System - Risk Selection and Two-tier Medicine","type":"project"},{"authors":null,"categories":null,"content":"     ","date":1409011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573159340,"objectID":"1dc16b4cda36fd0b457abef91d3f0dd4","permalink":"https://bodoburger.github.io/project/2013-minimum-wages/","publishdate":"2014-08-26T00:00:00Z","relpermalink":"/project/2013-minimum-wages/","section":"project","summary":"Literature review on minimum wage studies in the US. Does the result apply to the German labour market?","tags":["Economics"],"title":"Measuring the effects of a general minimum wage","type":"project"},{"authors":["Bodo Burger"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572808667,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://bodoburger.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572808667,"objectID":"aa33042543f9be1425c7a5f568cde8f5","permalink":"https://bodoburger.github.io/aboutme/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/aboutme/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572808667,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://bodoburger.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585064454,"objectID":"55020b0be9fb45733e8cdc0affcf049b","permalink":"https://bodoburger.github.io/my-projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/my-projects/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572808667,"objectID":"2f1b668aeb87cc9ad12adfd7cbfb9bd5","permalink":"https://bodoburger.github.io/zzz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zzz/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"AWS Analytics Services  Amazon ElasticSearch  search engine https://aws.amazon.com/elasticsearch-service/faqs/ https://en.wikipedia.org/wiki/Elasticsearch   Amazon Elastic MapReduce  process vast amounts of data using Hadoop framework https://aws.amazon.com/emr/faqs/ https://en.wikipedia.org/wiki/Apache_Hadoop   Amazon Kinesis  collect, process, and analyze video and data streams in real time Kinesis Data Firehose   Amazon Redshift  data warehouse: https://en.wikipedia.org/wiki/Data_warehouse   Amazon Athena  interactive query service using standard SQL for data stored in S3 instance    AWS Compute Services  Amazon Elastic Compute Cloud (EC2)  resizable compute capacity in the cloud different instance types with varying hardware configurations (A1, T3, T2, M5, \u0026hellip;)   Amazon Lightsail  virtual private servers SSD-based storage, data transfer, DNS management, and a static IP   Amazon Elastic Container Service (ECS)  container management service using Docker https://de.wikipedia.org/wiki/Docker_(Software)   Amazon Lambda  run code without managing servers serverless computing natively supports Java, Go, PowerShell, Node.js, C#, Python, and Ruby code    AWS Database Services  Amazon DynamoDB  NoSQL database https://en.wikipedia.org/wiki/Amazon_DynamoDB   Amazon Relational Database Service (RDS)  manages relational database in the cloud supports Amazon Aurora, MySQL, MariaDB, Oracle, SQL Server, and PostgreSQL database engines   Amazon Redshift  data warehouse   Amazon Aurora  MySQL and PostgreSQL compatible relational database built for the cloud    AWS Developer Tools  Amazon CodeCommit  source control service using Git repositories   Amazon CodePipeline  continuous integration and continuous delivery builds, tests, and deploys code every time it is changed can be used with GitHub   Amazon CodeBuild  build and test code with continuous scaling   Amazon CodeDeploy  automates software deployments    AWS Management Tools  Amazon CloudFormation  model and provision all of your cloud infrastructure resources   Amazon CloudWatch  monitor resources and applications   Amazon Systems Manager Amazon CloudTrail  user activity    AWS Networking and Content Delivery Services  Amazon Virtual Private Cloud (VPC)  isolate cloud resources with your own private virtual network   Amazon Direct Connect  dedicated network connection between your network and your Amazon VPC   Amazon Route 53  cloud DNS to connect user requests to AWS resources   Amazon Elastic Load Balancing  distributes application traffic across EC2 instances   Amazon CloudFront  content delivery network (CDN)    AWS Storage Services   Amazon Elastic Block Storage (EBS)  Amazon Elastic File System (EFS)  store and share data in scalable file systems   Amazon S3  object storage   Amazon Glacier  archive data in low-cost storage    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576078779,"objectID":"32192d4c785ea59aa9cdffc3e8c7c416","permalink":"https://bodoburger.github.io/notes/cloud-services/aws/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/cloud-services/aws/","section":"notes","summary":"AWS Analytics Services  Amazon ElasticSearch  search engine https://aws.amazon.com/elasticsearch-service/faqs/ https://en.wikipedia.org/wiki/Elasticsearch   Amazon Elastic MapReduce  process vast amounts of data using Hadoop framework https://aws.amazon.com/emr/faqs/ https://en.wikipedia.org/wiki/Apache_Hadoop   Amazon Kinesis  collect, process, and analyze video and data streams in real time Kinesis Data Firehose   Amazon Redshift  data warehouse: https://en.wikipedia.org/wiki/Data_warehouse   Amazon Athena  interactive query service using standard SQL for data stored in S3 instance    AWS Compute Services  Amazon Elastic Compute Cloud (EC2)  resizable compute capacity in the cloud different instance types with varying hardware configurations (A1, T3, T2, M5, \u0026hellip;)   Amazon Lightsail  virtual private servers SSD-based storage, data transfer, DNS management, and a static IP   Amazon Elastic Container Service (ECS)  container management service using Docker https://de.","tags":null,"title":"Amazon Web Services Overview","type":"docs"},{"authors":null,"categories":null,"content":"Goal of data analysis Decision making often involves uncertainty (uncertain situations, uncertain impacts). We assume that existing data contains information that we can use to model uncertain situations, predict outcomes, or unknown parameters.\nRelated disciplines: statistics, artificial intelligence, machine learning, data mining and knowledge discovery, deep learning, reinforcement learning.\nKnowledge discovery process graph TD; A(databases or other data sources) B(data warehouse) C(task-relevant data) D(patterns) E(knowledge) A --\u0026gt;|data cleaning| B B --\u0026gt;|data selection| C C --\u0026gt;|data mining| D D --\u0026gt;|visualization| E  V model of big data The initial three V\u0026rsquo;s are:\n volume: huge amount of data so large that it cannot be analyzed using traditional methods; high number of instances or features variety: large proportion of data is unstructured; there are different types of data (e.g. spreadsheets, images, videos); different data formats velocity: data can be generated, changed and analyzed within short time spans (e.g. milliseconds)  Additionally suggested V\u0026rsquo;s:\n veracity / validity: credibility of the data, the high volume of data leads to different degrees of data quality; interfering factors can be noise, manipulation or misinterpretation value: added value by investments of companies in big data infrastructure  Different types of tasks  classification  e.g. image classification, document categorization   regression  e.g. housing values   clustering  e.g. customer segmentation   outlier detection frequent itemset mining  e.g. market-basket analysis   \u0026hellip;  Application examples  image recognition image processing speech recognition automatic translation game AIs:  Deepmind AlphaGo (go), AlphaZero (chess), AlphaStar (StarCraft) OpenAI Five (Dota2)   material requirement planning for manufacturing predict capacity utilisation of the passenger train (Deutsche Bahn)  Sources  Lecture Big Data Management and Analytics by Prof. Dr. Schubert, Ludwig-Maximilians-Universität München https://whatis.techtarget.com/definition/3Vs https://blog.unbelievable-machine.com/en/what-is-big-data-definition-five-vs  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"ce1aeec31cb1ab01f2db119bf3fdcf5a","permalink":"https://bodoburger.github.io/notes/big-data/big-data-basics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/big-data/big-data-basics/","section":"notes","summary":"Goal of data analysis Decision making often involves uncertainty (uncertain situations, uncertain impacts). We assume that existing data contains information that we can use to model uncertain situations, predict outcomes, or unknown parameters.\nRelated disciplines: statistics, artificial intelligence, machine learning, data mining and knowledge discovery, deep learning, reinforcement learning.\nKnowledge discovery process graph TD; A(databases or other data sources) B(data warehouse) C(task-relevant data) D(patterns) E(knowledge) A --\u0026gt;|data cleaning| B B --\u0026gt;|data selection| C C --\u0026gt;|data mining| D D --\u0026gt;|visualization| E  V model of big data The initial three V\u0026rsquo;s are:","tags":null,"title":"Basics","type":"docs"},{"authors":null,"categories":null,"content":"Create new environment and switch to it conda create -n name_of_new_env conda activate name_of_new_env  Create environment with specific python version:\nconda create -n name_of_new_env python 3.7  Remove environment conda remove -n name_of_env --all # alternative: conda env remove -n name_of_env  List all environments conda env list  Adding channels to environment Activate the environment, then:\nconda config --env --add channels conda-forge  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586362330,"objectID":"8908404f670cac5263ef9d4eab1272ae","permalink":"https://bodoburger.github.io/notes/anaconda/anaconda-environments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/anaconda/anaconda-environments/","section":"notes","summary":"Create new environment and switch to it conda create -n name_of_new_env conda activate name_of_new_env  Create environment with specific python version:\nconda create -n name_of_new_env python 3.7  Remove environment conda remove -n name_of_env --all # alternative: conda env remove -n name_of_env  List all environments conda env list  Adding channels to environment Activate the environment, then:\nconda config --env --add channels conda-forge  ","tags":null,"title":"Environments","type":"docs"},{"authors":null,"categories":null,"content":"  Documentation  Installer for Linux  bash ~/Downloads/Anaconda3-2019.03-Linux-x86_64.sh conda update conda conda update anaconda  Change kernel in jupyter Base environment needs the nb_conda_kernels package. Every environment needs the ipykernel package.\nconda install nb_conda_kernels  Deep learning environment Prereq:\nsudo apt-get install libhdf5-serial-dev # for saving keras models efficiently sudo apt install graphviz  conda create -n deeplearn source activate deeplearn conda install tensorflow-gpu conda install matplotlib yaml conda install opencv # needed for some examples conda install pydot # graphviz conda install pillow # python imaging library conda install cython # Why? conda install keras-gpu conda install ipykernel # for kernel selection in jupyter  Deeplearn Tensorflow 2.0 https://www.tensorflow.org/install/gpu\nconda install pip pip install tensorflow-gpu pip install tensorflow-datasets pip install matplotlib PyYAML opencv-python pydot pillow cython  Check tensorflow and keras gpu import tensorflow as tf tf.test.is_gpu_available( cuda_only=False, min_cuda_compute_capability=None ) from keras import backend as K K.tensorflow_backend._get_available_gpus()  Archived   Install TensorFlow with GPU Support the Easy Way  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"31baddc231166604d3f930ac54650f6e","permalink":"https://bodoburger.github.io/notes/anaconda/anaconda-install/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/anaconda/anaconda-install/","section":"notes","summary":"Documentation  Installer for Linux  bash ~/Downloads/Anaconda3-2019.03-Linux-x86_64.sh conda update conda conda update anaconda  Change kernel in jupyter Base environment needs the nb_conda_kernels package. Every environment needs the ipykernel package.\nconda install nb_conda_kernels  Deep learning environment Prereq:\nsudo apt-get install libhdf5-serial-dev # for saving keras models efficiently sudo apt install graphviz  conda create -n deeplearn source activate deeplearn conda install tensorflow-gpu conda install matplotlib yaml conda install opencv # needed for some examples conda install pydot # graphviz conda install pillow # python imaging library conda install cython # Why?","tags":null,"title":"Installing Anaconda","type":"docs"},{"authors":null,"categories":null,"content":"  Anaconda-FAQ on whether you should add Anaconda to the PATH  Temporarily To add Anaconda temporarily to the PATH, open a terminal and type:\nexport PATH=\u0026quot;/home/bodo/anaconda3/bin:$PATH\u0026quot;\nShow PATH:\necho $PATH\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"ca2996da4bdebcc05a775c3c7e31f9d2","permalink":"https://bodoburger.github.io/notes/anaconda/anaconda-path/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/anaconda/anaconda-path/","section":"notes","summary":"Anaconda-FAQ on whether you should add Anaconda to the PATH  Temporarily To add Anaconda temporarily to the PATH, open a terminal and type:\nexport PATH=\u0026quot;/home/bodo/anaconda3/bin:$PATH\u0026quot;\nShow PATH:\necho $PATH","tags":null,"title":"System Path","type":"docs"},{"authors":null,"categories":null,"content":"Update base environment conda update conda conda update anaconda  Update all packages conda update --all  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575586183,"objectID":"93641a7bd33caadc32a3fe8797a7e26d","permalink":"https://bodoburger.github.io/notes/anaconda/anaconda-update/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/anaconda/anaconda-update/","section":"notes","summary":"Update base environment conda update conda conda update anaconda  Update all packages conda update --all  ","tags":null,"title":"Updating Anaconda","type":"docs"}]